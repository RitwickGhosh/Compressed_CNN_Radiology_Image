{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tensorflow.keras.applications.vgg16 import VGG16 as cnn\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom keras.layers import Input, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\nval_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/val'\ntest_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test'\n# len(os.listdir('/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls /kaggle/input/chest-xray-pneumonia/chest_xray/test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = len(os.listdir(train_dir + '/NORMAL')) + len(os.listdir(train_dir + '/PNEUMONIA'))\nprint(nb_train_samples)\nnb_val_samples  = len(os.listdir(val_dir + '/NORMAL')) + len(os.listdir(val_dir + '/PNEUMONIA'))\nprint(nb_val_samples)\nnb_test_samples  = len(os.listdir(test_dir + '/NORMAL')) + len(os.listdir(val_dir + '/PNEUMONIA'))\nprint(nb_test_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                      shear_range=0.2,zoom_range=0.2,\n                                      horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(rescale = 1./255)\n\ntest_datagen = ImageDataGenerator(rescale=1./ 255)\n\nbatch_size = 10\nimg_width = 150\nimg_height = 150\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,batch_size = batch_size,\n                                                    class_mode = 'binary', \n                                                    target_size =(img_width, img_height))\n\nval_generator = val_datagen.flow_from_directory(val_dir,batch_size = batch_size,\n                                                    class_mode = 'binary', \n                                                    target_size =(img_width, img_height))\n\n\n\ntest_generator = test_datagen.flow_from_directory(test_dir,batch_size=batch_size,                                              \n                                                class_mode='binary',\n                                                target_size=(img_width, img_height))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"x_train,y_train=train_generator.next()\nx_test,y_test=test_generator.next(624)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n# Define path to the data directory\ndata_dir = Path('../input/chest-xray-pneumonia/chest_xray/chest_xray')\n\n# Path to train directory (Fancy pathlib...no more os.path!!)\ntrain_dir = data_dir / 'train'\nimport cv2\nfrom keras.utils import to_categorical\n# Path to validation directory\nval_dir = data_dir / 'val'\n\n# Path to test directory\ntest_dir = data_dir / 'test'\n\n#Get the path to the sub-directories\nnormal_cases_dir = train_dir / 'NORMAL'\npneumonia_cases_dir = train_dir / 'PNEUMONIA'\n\n# Get the list of all the images\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\n# List that are going to contain validation images data and the corresponding labels\nvalid_data = []\nvalid_labels = []\nimport numpy as np\n\n# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n# We will normalize the pixel values and resizing all the images to 224x224 \n\n# Normal cases\nfor img in normal_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (150,150))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150,150)).astype(np.float32)/255.0\n    label = to_categorical(0, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n                      \n# Pneumonia cases        \nfor img in pneumonia_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (150,150))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.0\n    label = to_categorical(1, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n    \n# Convert the list into numpy arrays\nx_train = np.array(valid_data)\ny_train = np.array(valid_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n# Define path to the data directory\ndata_dir = Path('../input/chest-xray-pneumonia/chest_xray/chest_xray')\n\n# Path to train directory (Fancy pathlib...no more os.path!!)\ntrain_dir = data_dir / 'train'\nimport cv2\nfrom keras.utils import to_categorical\n# Path to validation directory\nval_dir = data_dir / 'val'\n\n# Path to test directory\ntest_dir = data_dir / 'test'\n\n#Get the path to the sub-directories\nnormal_cases_dir = test_dir / 'NORMAL'\npneumonia_cases_dir = test_dir / 'PNEUMONIA'\n\n# Get the list of all the images\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\n# List that are going to contain validation images data and the corresponding labels\nvalid_data = []\nvalid_labels = []\nimport numpy as np\n\n# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n# We will normalize the pixel values and resizing all the images to 224x224 \n\n# Normal cases\nfor img in normal_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (150,150))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (150,150)).astype(np.float32)/255.0\n    label = to_categorical(0, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n                      \n# Pneumonia cases        \nfor img in pneumonia_cases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (150,150))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)/255.0\n    label = to_categorical(1, num_classes=2)\n    valid_data.append(img)\n    valid_labels.append(label)\n    \n# Convert the list into numpy arrays\nx_test = np.array(valid_data)\ny_test = np.array(valid_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_shape = Input(shape=(150,150,3))\nmodel = cnn(weights = 'imagenet',input_shape=(150,150,3), include_top=False)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will freeze all layers of our pretrained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n      layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlast_output = model.output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense(2, activation='sigmoid')(x)           \n\nmodel = Model(model.input, x) \n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"model=cnn(weights=None, include_top=True,classes=2,input_shape=(150,150,3))\nmodel.summary()"},{"metadata":{"trusted":true},"cell_type":"code","source":"#sgd=SGD(lr=0.01,momentum=0.9,nesterov=True)\n#model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n\nmodel.compile(optimizer = Adam(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"history = model.fit_generator(\n            train_generator,\n            validation_data = val_generator,\n            steps_per_epoch = nb_train_samples // batch_size,\n            epochs = 1,\n            validation_steps = nb_val_samples // batch_size,\n            verbose = 1)\n\nhis=model.fit(x_train, y_train, validation_split=0.2, epochs=1, batch_size=10)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhistory=model.fit(x_train,y_train, validation_data=(x_test,y_test), epochs=10, batch_size=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test, y_test,batch_size=10)\nprint(score[1])\n# evaluate the model\n#scores = model.evaluate_generator(test_generator)\n#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"/kaggle/working/vgg16model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(score[1]*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.cluster import KMeans\nimport tensorflow.keras as keras\nfrom copy import deepcopy\nimport numpy as np\nimport h5py\nfrom collections import defaultdict, namedtuple\nfrom heapq import heappush, heappop, heapify\nimport struct\n\n\nCOMPRESSION_RATE = 0.1\nBATCH_SIZE = 10\nNUM_BATCHES = 521\nNUM_EPOCH = 1\nBITS = 5\nMAX_SPAN = 2 ** BITS\nLEARNING_RATE = 0.001\n\n\ndef get_batch(batch_size):\n    index = np.random.randint(0, np.shape(x_train)[0], batch_size)\n    return x_train[index, :], y_train[index]\n\n\ndef prune_weights(weight):\n    for i in range(weight.shape[-1]):\n        tmp = deepcopy(weight[..., i])\n        tmp = np.abs(tmp)\n        tmp = np.sort(np.array(tmp))\n        # compute threshold\n        threshold = tmp[int(tmp.shape[0] * COMPRESSION_RATE)]\n        weight[..., i][np.abs(weight[..., i]) < threshold] = 0\n    sparse_matrix = deepcopy(weight)\n    sparse_matrix[sparse_matrix != 0] = 1\n    return weight, sparse_matrix\n\n\nSparse_layer = {}\n\n# Pruning\nfor layer_id in range(len(model.layers)):\n    layer = model.layers[layer_id]\n    weight = layer.get_weights()\n    # weight:weight[0]\n    # bias:weight[1]\n    if len(weight) > 0:\n        if layer_id != 0:\n            w = deepcopy(weight)\n            new_weight, sparse_matrix = prune_weights(w[0])\n            Sparse_layer[layer_id] = sparse_matrix\n            w[0] = new_weight\n            layer.set_weights(w)\n\n#scores = model.evaluate_generator(test_generator)\n#print(scores[1])\n            \n            \nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(score[1]*100)\n\n# Retrain\nfor epoch in range(NUM_EPOCH):\n    for j in range(x_train.shape[0] // BATCH_SIZE):\n        begin = j*BATCH_SIZE\n        if j*BATCH_SIZE + BATCH_SIZE > x_train.shape[0]:\n            end = x_train.shape[0]\n        else:\n            end = j*BATCH_SIZE + BATCH_SIZE\n        X, Y = x_train[begin:end], y_train[begin:end]\n        # train on each batch\n        model.train_on_batch(X, Y)\n        # apply Sparse connection\n        for layer_id in Sparse_layer:\n            w = model.layers[layer_id].get_weights()\n            w[0] = w[0] * Sparse_layer[layer_id]\n            model.layers[layer_id].set_weights(w)\n    score = model.evaluate(x_test, y_test, verbose=0)\n    print('val loss: {}'.format(score[0]))\n    print('val acc: {}'.format(score[1]))\n\n\n    \n#scores = model.evaluate_generator(test_generator)\n#print(scores[1])\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(score[1]*100)\n\ncluster_index = dict()\ncluster_centroids = dict()\n\n\n# Weight Share and Quantization\nfor layer_id in Sparse_layer:\n    layer = model.layers[layer_id]\n    weight = layer.get_weights()\n    w = deepcopy(weight)\n    shape = w[0].shape\n\n    weight_array = w[0].flatten()\n    nonzero_weight = w[0][Sparse_layer[layer_id] != 0].flatten()\n    nonzero_index = np.where(Sparse_layer[layer_id].flatten() != 0)[0]\n\n    max_weight = max(nonzero_weight)\n    min_weight = min(nonzero_weight)\n    space = np.linspace(min_weight, max_weight, num=2 ** BITS)\n    kmeans = KMeans(n_clusters=len(space), init=space.reshape(-1, 1), n_init=1, precompute_distances=True,\n                    algorithm=\"full\")\n    kmeans.fit(nonzero_weight.reshape(-1, 1))\n    # cluster index of each weight\n    layer_cluster_index = kmeans.labels_\n    # value of the centroids\n    layer_centroids = kmeans.cluster_centers_.flatten()\n    # Add to dict\n    cluster_index[layer_id] = layer_cluster_index\n    cluster_centroids[layer_id] = layer_centroids\n\n    # set new weight\n    new_weight = kmeans.cluster_centers_[kmeans.labels_].flatten()\n    for idx in range(len(nonzero_index)):\n        index = nonzero_index[idx]\n        weight_array[index] = new_weight[idx]\n    # new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(shape)\n    # w[0] = new_weight\n    w[0] = weight_array.reshape(shape)\n    layer.set_weights(w)\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(score[1])\n\n\n# calculate gradient and get the fine-tuned centroids\n# for epoch in range(NUM_EPOCH):\n#     for j in range(x_train.shape[0] // BATCH_SIZE):\n#         begin = j * BATCH_SIZE\n#         if j * BATCH_SIZE + BATCH_SIZE > x_train.shape[0]:\n#             end = x_train.shape[0]\n#         else:\n#             end = j * BATCH_SIZE + BATCH_SIZE\n#         X, Y = x_train[begin:end], y_train[begin:end]\n#         with tf.GradientTape() as tape:\n#             y_predict = model(X)\n#             loss = tf.losses.softmax_cross_entropy(onehot_labels=Y, logits=y_predict)\n#         grads = tape.gradient(loss, model.variables)\n#         gradient_num = 0\n#         for layer_id in Sparse_layer:\n#             gradient_num += 2\n#             gradient = grads[gradient_num].numpy().flatten()\n#\n#             # Get the gradient of the nonzero position\n#             nonzero_gradient = gradient[Sparse_layer[layer_id].flatten() != 0].flatten()\n#             nonzero_index = np.where(Sparse_layer[layer_id].flatten() != 0)[0]\n#             # print(len(nonzero_gradient))\n#\n#             gradient_index = np.zeros(2 ** BITS)\n#             # Calculate the sum of gradient of the same cluster\n#             for i in range(len(nonzero_gradient)):\n#                 gradient_index[cluster_index[layer_id][i]] += gradient[i]\n#             # Update centroid\n#             fine_tuned_centroids = cluster_centroids[layer_id]-LEARNING_RATE*gradient_index\n#             cluster_centroids[layer_id] = fine_tuned_centroids\n#\n#             w = model.layers[layer_id].get_weights()\n#             shape = w[0].shape\n#             weight_array = w[0].flatten()\n#             new_weight = fine_tuned_centroids[cluster_index[layer_id]]\n#             for idx in range(len(nonzero_index)):\n#                 index = nonzero_index[idx]\n#                 weight_array[index] = new_weight[idx]\n#\n#             w[0] = weight_array.reshape(shape)\n#             model.layers[layer_id].set_weights(w)\n#     score = model.evaluate(x_test, y_test, verbose=0)\n#     print('val loss: {}'.format(score[0]))\n#     print('val acc: {}'.format(score[1]))\n\n\nprint('-------------------')\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(score[1])\n\n\nlayer_relative_index = dict()\nlayer_weight_cluster_index = dict()\n\nNode = namedtuple('Node', ['frequency', 'value', 'left', 'right'])\nNode.__lt__ = lambda x, y: x.frequency < y.frequency\n\n\ndef encode_huffman_tree(root):\n    \"\"\"\n    Encodes a huffman tree to string of '0's and '1's\n    \"\"\"\n    # converter = {'float32':float2bitstr, 'int32':int2bitstr}\n    code_list = []\n\n    def encode_node(node):\n        if node.value is not None:  # node is leaf node\n            code_list.append('1')\n            lst = list(int2bitstr(node.value))\n            code_list.extend(lst)\n        else:\n            code_list.append('0')\n            encode_node(node.left)\n            encode_node(node.right)\n\n    encode_node(root)\n    return ''.join(code_list)\n\n\ndef int2bitstr(integer):\n    four_bytes = struct.pack('>I', integer)  # bytes\n    return ''.join(f'{byte:08b}' for byte in four_bytes)  # string of '0's and '1's\n\n\ndef bitstr2int(bitstr):\n    byte_arr = bytearray(int(bitstr[i:i + 8], 2) for i in range(0, len(bitstr), 8))\n    return struct.unpack('>I', byte_arr)[0]\n\n\ndef huffman_encode(arr):\n    # count the frequency of each number in array\n    frequency_map = defaultdict(int)\n    for value in np.nditer(arr):\n        value = int(value)\n        frequency_map[value] += 1\n\n    heap = [Node(frequency, value, None, None) for value, frequency in frequency_map.items()]\n    heapify(heap)\n\n    # Merge nodes\n    while len(heap) > 1:\n        node1 = heappop(heap)\n        node2 = heappop(heap)\n        merged = Node(node1.frequency + node2.frequency, None, node1, node2)\n        heappush(heap, merged)\n\n    # Generate code value mapping\n    value2code = dict()\n\n    def generate_code(node, code):\n        if node is None:\n            return\n        if node.value is not None:\n            value2code[node.value] = code\n            return\n        generate_code(node.left, code + '0')\n        generate_code(node.right, code + '1')\n\n    root = heappop(heap)\n    generate_code(root, '')\n\n    data_encoding = ''.join(value2code[int(value)] for value in np.nditer(arr))\n\n    codebook_encoding = encode_huffman_tree(root)\n\n    return data_encoding, codebook_encoding\n\n\n# Matrix sparsity with relative index\nfor layer_id in Sparse_layer:\n    layer = model.layers[layer_id]\n    weight = layer.get_weights()\n    w = deepcopy(weight)\n    shape = w[0].shape\n\n    weight_array = w[0].flatten()\n    # nonzero_weight = w[0][Sparse_layer[layer_id] != 0].flatten()\n    # print(len(nonzero_weight))\n    nonzero_weight_cluster_index = cluster_index[layer_id]\n    print(len(nonzero_weight_cluster_index))\n    nonzero_index = np.where(Sparse_layer[layer_id].flatten() != 0)[0]\n\n    first = nonzero_index[0]\n\n    relative = np.insert(np.diff(nonzero_index), 0, first)\n\n    relative_diff_index = relative.tolist()\n\n    weight_cluster_index = nonzero_weight_cluster_index.tolist()\n\n    shift = 0\n    for i in np.where(relative > MAX_SPAN)[0].tolist():\n        while relative_diff_index[i + shift] > MAX_SPAN:\n            relative_diff_index.insert(i + shift, MAX_SPAN)\n            weight_cluster_index.insert(i + shift, 0)\n            shift += 1\n            relative_diff_index[i + shift] -= MAX_SPAN\n\n    layer_relative_index[layer_id] = np.array(relative_diff_index)\n    data_encoding, codebook_encoding = huffman_encode(np.array(weight_cluster_index))\n    # layer_weight_cluster_index[layer_id] = np.array(weight_cluster_index)\n    layer_weight_cluster_index[layer_id] = np.array([data_encoding, codebook_encoding])\n    print('----------------')\n\n# print(layer_weight_value[5])\n\n# encode\nfile_name = '/kaggle/working/deep_compression'\nfile = h5py.File('{}.h5'.format(file_name), mode='w')\n\nfor layer_id in range(len(model.layers)):\n    layer = model.layers[layer_id]\n    weight = layer.get_weights()\n    if len(weight) > 0:\n        file_layer = file.create_group(layer.name)\n        shape = weight[0].shape\n        if layer_id != 0:\n            print(len(weight[0].shape))\n            pshape = file_layer.create_dataset('shape', np.array(shape).shape, dtype='int32')\n            pindex = file_layer.create_dataset('index', layer_relative_index[layer_id].shape, dtype='int32')\n            # pcluster_index = file_layer.create_dataset('cluster_index', layer_weight_cluster_index[layer_id].shape,\n            #                                            dtype='int32')\n            pcluster_index = file_layer.create_dataset('cluster_index', layer_weight_cluster_index[layer_id].shape,\n                                                       dtype=h5py.special_dtype(vlen=str))\n\n            pcentroid = file_layer.create_dataset('centroid', cluster_centroids[layer_id].shape, dtype='float32')\n            pshape[:] = np.array(shape)\n            pindex[:] = layer_relative_index[layer_id]\n            pcluster_index[:] = layer_weight_cluster_index[layer_id]\n            pcentroid[:] = cluster_centroids[layer_id]\n        else:\n            pweight = file_layer.create_dataset('weight', weight[0].shape, dtype='float32')\n            pweight[:] = weight[0]\n        pbias = file_layer.create_dataset('bias', weight[1].shape, dtype='float32')\n        pbias[:] = weight[1]\n\nfile.flush()\nfile.close()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}